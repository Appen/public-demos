{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acknowledged-scale",
   "metadata": {},
   "source": [
    "# Tutorial - Using Appen Annotated Data with NVIDIA Transfer Learning Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-capture",
   "metadata": {},
   "source": [
    "The annnotated data generated with ADAP can also be used with NVIDIA's Transfer Learning Toolkit (TLT). TLT is a python based AI toolkit for customizing pre-trained AI models with your own data. TLT allows you to train, fine tune, prune and export highly optimized and accurate AI models for edge deployment by adapting popular network architectures and backbones to your data.\n",
    "\n",
    "Our [previous tutorial](./Tutorial%20-%20Annotate%20Objects%20In%20An%20Image%20Using%20A%20Bounding%20Box%20with%20the%20Appen%20Data%20Annotation%20Platform.ipynb) explains how to generate annotations using ADAP in the Pascal VOC format for the coco-animals dataset. In this tutorial, we use that data to train an object detection model using NVIDIA's TLT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-default",
   "metadata": {},
   "source": [
    "The Transfer Learning Toolkit provides various object detection models to fine tune from:\n",
    "- [Transfer Learning with Object Detection](https://ngc.nvidia.com/catalog/models/nvidia:tlt_pretrained_object_detection) with common architectures like YOLOV3, FasterRCNN, SSD, DSSD, and RetinaNet. \n",
    "- [Transfer Learning with Detectnet v2](https://ngc.nvidia.com/catalog/models/nvidia:tlt_pretrained_detectnet_v2) \n",
    "\n",
    "For simplicity, we create a YOLOV3 model using NVIDIA's instructions [here](https://developer.nvidia.com/blog/preparing-state-of-the-art-models-for-classification-and-object-detection-with-tlt/) and [here](https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/text/quickstart/deepstream_integration.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fresh-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from xml_to_kitti import xml_to_kitti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-limit",
   "metadata": {},
   "source": [
    "## Convert Annotations from Pascal VOC to Kitti format\n",
    "We use the [xml_to_kitti.py](./xml_to_kitti.py) helper script to convert our annotations into KITTI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "future-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classes in our coco-animals example\n",
    "classes = ['bear', \"bird\", \"cat\", \"dog\", \"giraffe\", \"horse\", \"sheep\", \"zebra\"]\n",
    "\n",
    "# The path to the dataset and Pascal annotations\n",
    "pascal_annotations_folder = \"/Users/rparundekar/Downloads/coco-animals/annotations\"\n",
    "pascal_train_annotations_folder = os.path.join(pascal_annotations_folder, \"train\")\n",
    "pascal_val_annotations_folder = os.path.join(pascal_annotations_folder, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afraid-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dirs for kitti format\n",
    "kitti_annotations_folder = \"/Users/rparundekar/Downloads/coco-animals/kitti_annotations\"\n",
    "kitti_train_annotations_folder = os.path.join(kitti_annotations_folder, \"train\")\n",
    "kitti_val_annotations_folder = os.path.join(kitti_annotations_folder, \"val\")\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(kitti_annotations_folder):\n",
    "    os.makedirs(kitti_annotations_folder)\n",
    "# Also create train and val folders\n",
    "if not os.path.exists(kitti_train_annotations_folder):\n",
    "    os.makedirs(kitti_train_annotations_folder)\n",
    "if not os.path.exists(kitti_val_annotations_folder):\n",
    "    os.makedirs(kitti_val_annotations_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raised-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and val data to kitti\n",
    "xml_to_kitti(input_dir=pascal_train_annotations_folder, output_dir=kitti_train_annotations_folder, encode_difficult=\"0\", classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/rparundekar/Downloads/coco-animals/kitti_annotations/train/COCO_train2014_000000468017.txt\n",
      "Contents:\n",
      "horse 0 0 0 110 74 232 222 0 0 0 0 0 0 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print one file content from the training set\n",
    "for filename in glob.glob(os.path.join(kitti_annotations_folder, 'train', \"*.txt\")):\n",
    "    print(f\"File: {filename}\")\n",
    "    print(f\"Contents:\")\n",
    "    with open(os.path.join(kitti_annotations_folder, 'train', filename), \"r\") as f:\n",
    "        print(f.read())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-north",
   "metadata": {},
   "source": [
    "## Training with TLT \n",
    "\n",
    "Following the instructions [here](https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/text/quickstart/deepstream_integration.html#), let's first download the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-domestic",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/tlt_cv_samples/versions/v1.0.2/zip -O tlt_cv_samples_v1.0.2.zip\n",
    "\n",
    "$ unzip -u tlt_cv_samples_v1.0.2.zip  -d ./tlt_cv_samples_v1.0.2 && rm -rf tlt_cv_samples_v1.0.2.zip && cd ./tlt_cv_samples_v1.0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-charlotte",
   "metadata": {},
   "source": [
    "Once the notebook samples are downloaded, you may start the notebook using below commands:\n",
    "```    \n",
    "$ jupyter notebook --ip 0.0.0.0 --port 8888 --allow-root\n",
    "```\n",
    "\n",
    "Open the internet browser on localhost and open the url written below:\n",
    "```\n",
    "http://0.0.0.0:8888\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-sampling",
   "metadata": {},
   "source": [
    "Since we are creating a YOLOv3 model, open the `yolo_v3/yolo_v3.ipynb` Notebook. Follow the Notebook instructions to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-operations",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
